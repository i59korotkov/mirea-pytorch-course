{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjM7DFps2rBi"
      },
      "source": [
        "# **Занятие 2.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlS1ciOPBg7g"
      },
      "source": [
        "# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP06X1SrzLlm"
      },
      "source": [
        "[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n",
        "\n",
        "[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n",
        "\n",
        "[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n",
        "\n",
        "[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alR-VHX_gnQK"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipOjjh8OCk4u"
      },
      "outputs": [],
      "source": [
        "def show_tensor_params(*tensors):\n",
        "  for x in tensors:\n",
        "    print('---')\n",
        "    print(f\"data - {x.data}\")\n",
        "    print(f\"grad - {x.grad}\")\n",
        "    print(f\"grad_fn - {x.grad_fn}\")\n",
        "    print(f\"req_grad - {x.requires_grad}\")\n",
        "    print(f\"is_leaf - {x.is_leaf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXas0qEnybl9",
        "outputId": "1651d3e4-b6b2-4a5a-c790-7985e017abdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "data - 5.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(5.0)\n",
        "show_tensor_params(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuymHxbjzDfP"
      },
      "source": [
        "All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n",
        "\n",
        "For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n",
        "\n",
        "Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5NE4zRPyqTT"
      },
      "outputs": [],
      "source": [
        "#Slide A4\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0)\n",
        "c = a*b\n",
        "\n",
        "c.backward()\n",
        "# (2 * c).backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-TbdvmH-oaM",
        "outputId": "51f1335d-acef-4fec-a7e8-821804f5b5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 3.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - None\n",
            "grad_fn - <MulBackward0 object at 0x7fbee0481c70>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n"
          ]
        }
      ],
      "source": [
        "show_tensor_params(a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqUcFO2rCXni"
      },
      "outputs": [],
      "source": [
        "#Slide Simple5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYTsuKc3Fn8r"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "\n",
        "# c.retain_grad()\n",
        "# e.retain_grad()\n",
        "e.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egTBJvIBF5EO",
        "outputId": "5e2399eb-d24b-44d4-dc9e-0ed38d067d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 12.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - 8.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - None\n",
            "grad_fn - <MulBackward0 object at 0x7fbe6ef85670>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 4.0\n",
            "grad - 6.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 24.0\n",
            "grad - None\n",
            "grad_fn - <MulBackward0 object at 0x7fbe6eff7d90>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        }
      ],
      "source": [
        "show_tensor_params(a, b, c, d, e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "W5Cs2_REGgOS",
        "outputId": "09109330-60a9-424f-b689-956ad010ddce"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3de2fcb7bcd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ],
      "source": [
        "#In place 1\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WeqfWzYGhKG",
        "outputId": "4038ec79-1992-430f-fc66-402dc936cc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLZ3Z4qIH4J4"
      },
      "outputs": [],
      "source": [
        "#In place 2\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c+d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ySSjlRUIH0e",
        "outputId": "b935044e-9dce-4ed8-8877-f60705f202a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jbSqPGkILEw"
      },
      "outputs": [],
      "source": [
        "# отвязка от графа\n",
        "k = e.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLKUQ08AJhZT",
        "outputId": "e9a13647-397d-4b01-e56d-e732a83b5ff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.storage == e.storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqo-PW2kJkaG",
        "outputId": "0c2be4e0-9d2a-42be-b5ea-49c9c88bc60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - <AddBackward0 object at 0x7fbe6ef85e80>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        }
      ],
      "source": [
        "show_tensor_params(e, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8urvcsAKi62"
      },
      "source": [
        "# Создание собственной библиотеки автоматического дифференцирования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txwYkEHMftme"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urGQXw9GgdQt"
      },
      "source": [
        "### Простой пример"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPNsEPbZfwXm"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "  return 3*x**2 - 4*x + 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKMjYubGfzo5",
        "outputId": "582faa76-e61b-4d89-ee5e-e4337f3c5ca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(3.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2Mufja5Mf2dD",
        "outputId": "23439d4e-9be5-427d-d34b-5fd2dc039ba2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f835f283eb0>]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "xs = np.arange(-5, 5, 0.25)\n",
        "ys = f(xs)\n",
        "plt.plot(xs, ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzRAdjhFgGo8",
        "outputId": "d82d0287-1b7e-414d-d47d-929e2098eb6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.000003001384925"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h = 0.000001\n",
        "x = 2\n",
        "(f(x + h) - f(x))/h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOszwXaTgkd4"
      },
      "source": [
        "### Более сложный пример"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOzPl8NWghve",
        "outputId": "35c06a3d-cbab-4e6f-b6de-7dbf946a0086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.0\n"
          ]
        }
      ],
      "source": [
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "d = a*b + c\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Xx4_omgrkm",
        "outputId": "fdf2f002-1354-49ce-dbf8-b9cbdd854a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d1 4.0\n",
            "d2 4.0001\n",
            "slope 0.9999999999976694\n"
          ]
        }
      ],
      "source": [
        "h = 0.0001\n",
        "\n",
        "# inputs\n",
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "\n",
        "d1 = a*b + c\n",
        "c += h\n",
        "d2 = a*b + c\n",
        "\n",
        "print('d1', d1)\n",
        "print('d2', d2)\n",
        "print('slope', (d2 - d1)/h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlDJrMMsOgNh"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPyPkdq5RH94"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5-hnsEiPIz9"
      },
      "outputs": [],
      "source": [
        "class Exp(Function):\n",
        "  \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, i):\n",
        "    \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "    \"\"\"\n",
        "    result = i.exp()\n",
        "    ctx.save_for_backward(result)\n",
        "    return result\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "    \"\"\"\n",
        "    print(ctx.saved_tensors)\n",
        "    result, = ctx.saved_tensors\n",
        "    return grad_output * result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elaOA8bdRiMc",
        "outputId": "99468a14-d9aa-4db5-d745-38b1b549748b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7.3891, grad_fn=<ExpBackward>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use it by calling the apply method\n",
        "input = torch.tensor(2.0, requires_grad=True)\n",
        "output = Exp.apply(input)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlcZLt-RSGgG",
        "outputId": "a91f98dd-08aa-4aad-915c-c03f29855b65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.38905609893065"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "math.exp(2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om6dn414SQeA",
        "outputId": "8f70848f-d6d3-4797-b4ff-0d5e449e7365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
            "---\n",
            "data - 7.389056205749512\n",
            "grad - None\n",
            "grad_fn - <torch.autograd.function.ExpBackward object at 0x7f82e5540040>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 2.0\n",
            "grad - 7.389056205749512\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-168b1ceafb31>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"grad - {x.grad}\")\n"
          ]
        }
      ],
      "source": [
        "output.backward()\n",
        "show_tensor_params(output)\n",
        "show_tensor_params(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_14IqfeSnLM"
      },
      "source": [
        "**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5cNegVYOd8u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Polynomial(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        result = 2.5 * input**3 - 1.5 * input\n",
        "        ctx.save_for_backward(input)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input = ctx.saved_tensors[0]\n",
        "        result = 7.5 * input**2 - 1.5\n",
        "        return grad_output * result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVqfE7p2lZXn",
        "outputId": "93fcef09-58ec-4d03-8649-16503e14b37b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<PolynomialBackward>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use it by calling the apply method\n",
        "input = torch.tensor(2.0, requires_grad=True)\n",
        "output = Polynomial.apply(input)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owb3Pbu_ljdJ",
        "outputId": "bc8f831c-e7af-4c28-e8ed-a73abde2abcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.5 * (5 * 2**3 - 3*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jaqv6RKnlbc9",
        "outputId": "c06a0ad2-286c-4700-94df-06667037cfda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "data - 17.0\n",
            "grad - None\n",
            "grad_fn - <torch.autograd.function.PolynomialBackward object at 0x7f82e5540400>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 2.0\n",
            "grad - 28.5\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-168b1ceafb31>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"grad - {x.grad}\")\n"
          ]
        }
      ],
      "source": [
        "output.backward()\n",
        "show_tensor_params(output)\n",
        "show_tensor_params(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsYqImnZl9Lw",
        "outputId": "47761435-541c-47d0-94d3-9fa0c03aecf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28.5"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "7.5 * 2**2 - 1.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA2PNhudUNij"
      },
      "source": [
        "Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chDdD9oSUlUJ"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "\n",
        "class Value:\n",
        "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
        "\n",
        "    def __init__(self, data: Union[int, float], _children=(), _op=''):\n",
        "        self.data = data\n",
        "        self.grad = 0\n",
        "        # internal variables used for autograd graph construction\n",
        "        self._backward = lambda: None # function \n",
        "        self._prev = set(_children) # set of Value objects\n",
        "        self._op = _op # the op that produced this node, string ('+', '-', ....)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(\n",
        "            data=self.data + other.data,\n",
        "            _children=(self, other),\n",
        "            _op='+',\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad\n",
        "            other.grad += out.grad\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(\n",
        "            data=self.data * other.data,\n",
        "            _children=(self, other),\n",
        "            _op='*',\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad * other.data\n",
        "            other.grad += out.grad * self.data\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
        "        out = Value(\n",
        "            data=self.data ** other,\n",
        "            _children=(self,),\n",
        "            _op='^',\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad * other * self.data**(other-1)\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def relu(self):\n",
        "        out = Value(\n",
        "            data=self.data if self.data > 0 else 0,\n",
        "            _children=(self,),\n",
        "            _op='relu'\n",
        "        )\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad * int(self.data > 0)\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self):\n",
        "\n",
        "        # topological order all of the children in the graph\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                print(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "        build_topo(self)\n",
        "\n",
        "        # go one variable at a time and apply the chain rule to get its gradient\n",
        "        self.grad = 1\n",
        "        for v in reversed(topo):\n",
        "            v._backward()\n",
        "\n",
        "    def __neg__(self): # -self\n",
        "        return self * -1\n",
        "\n",
        "    def __radd__(self, other): # other + self\n",
        "        return self + other\n",
        "\n",
        "    def __sub__(self, other): # self - other\n",
        "        return self + (-other)\n",
        "\n",
        "    def __rsub__(self, other): # other - self\n",
        "        return other + (-self)\n",
        "\n",
        "    def __rmul__(self, other): # other * self\n",
        "        return self * other\n",
        "\n",
        "    def __truediv__(self, other): # self / other\n",
        "        return self * other**-1\n",
        "\n",
        "    def __rtruediv__(self, other): # other / self\n",
        "        return other * self**-1\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Value(data={self.data}, grad={self.grad})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY7OzWjuUiaa"
      },
      "outputs": [],
      "source": [
        "def test_sanity_check():\n",
        "\n",
        "    x = Value(-4.0)\n",
        "    z = 2 * x + 2 + x\n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xmg, ymg = x, y\n",
        "\n",
        "    x = torch.Tensor([-4.0]).double()\n",
        "    x.requires_grad = True\n",
        "    z = 2 * x + 2 + x\n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xpt, ypt = x, y\n",
        "\n",
        "    # forward pass went well\n",
        "    assert ymg.data == ypt.data.item()\n",
        "    # backward pass went well\n",
        "    print(xmg, xpt, xpt.grad)\n",
        "    assert xmg.grad == xpt.grad.item()\n",
        "\n",
        "\n",
        "def test_more_ops():\n",
        "\n",
        "    a = Value(-4.0)\n",
        "    b = Value(2.0)\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c += c + 1\n",
        "    c += 1 + c + (-a)\n",
        "    d += d * 2 + (b + a).relu()\n",
        "    d += 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g += 10.0 / f\n",
        "    g.backward()\n",
        "    amg, bmg, gmg = a, b, g\n",
        "\n",
        "    a = torch.Tensor([-4.0]).double()\n",
        "    b = torch.Tensor([2.0]).double()\n",
        "    a.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c = c + c + 1\n",
        "    c = c + 1 + c + (-a)\n",
        "    d = d + d * 2 + (b + a).relu()\n",
        "    d = d + 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g = g + 10.0 / f\n",
        "    g.backward()\n",
        "    apt, bpt, gpt = a, b, g\n",
        "\n",
        "    tol = 1e-6\n",
        "    # forward pass went well\n",
        "    assert abs(gmg.data - gpt.data.item()) < tol\n",
        "    # backward pass went well\n",
        "    assert abs(amg.grad - apt.grad.item()) < tol\n",
        "    assert abs(bmg.grad - bpt.grad.item()) < tol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LgTiYeZ-WGk"
      },
      "outputs": [],
      "source": [
        "a = Value(-4.0)\n",
        "b = Value(2.0)\n",
        "d = Value(3.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0svSAs2h0Ap",
        "outputId": "d781482b-48db-47b6-c4a1-69ada2ff138c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value(data=-6.0, grad=0)\n",
            "Value(data=-2.0, grad=0)\n",
            "Value(data=-4.0, grad=0)\n",
            "Value(data=2.0, grad=0)\n",
            "Value(data=3.0, grad=0)\n"
          ]
        }
      ],
      "source": [
        "c = a + b\n",
        "e = c * d\n",
        "e.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9n8DN6RYkrx",
        "outputId": "e1e492dc-b0db-4fc7-d89e-a7bc8c528b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value(data=-20.0, grad=0)\n",
            "Value(data=-160.0, grad=0)\n",
            "Value(data=40.0, grad=0)\n",
            "Value(data=40.0, grad=0)\n",
            "Value(data=-10.0, grad=0)\n",
            "Value(data=-4.0, grad=0)\n",
            "Value(data=-6.0, grad=0)\n",
            "Value(data=-8.0, grad=0)\n",
            "Value(data=2, grad=0)\n",
            "Value(data=2, grad=0)\n",
            "Value(data=0, grad=0)\n",
            "Value(data=140.0, grad=0)\n",
            "Value(data=100.0, grad=0)\n",
            "Value(data=100.0, grad=0)\n",
            "Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "test_sanity_check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T198QDQYh_q",
        "outputId": "f3df93f7-7239-4315-f2ec-f640a8c35b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value(data=24.70408163265306, grad=0)\n",
            "Value(data=24.5, grad=0)\n",
            "Value(data=0.5, grad=0)\n",
            "Value(data=49.0, grad=0)\n",
            "Value(data=-7.0, grad=0)\n",
            "Value(data=-1.0, grad=0)\n",
            "Value(data=2.0, grad=0)\n",
            "Value(data=-2.0, grad=0)\n",
            "Value(data=1, grad=0)\n",
            "Value(data=-3.0, grad=0)\n",
            "Value(data=-1.0, grad=0)\n",
            "Value(data=1, grad=0)\n",
            "Value(data=-2.0, grad=0)\n",
            "Value(data=-4.0, grad=0)\n",
            "Value(data=2.0, grad=0)\n",
            "Value(data=4.0, grad=0)\n",
            "Value(data=-1, grad=0)\n",
            "Value(data=-6.0, grad=0)\n",
            "Value(data=6.0, grad=0)\n",
            "Value(data=6.0, grad=0)\n",
            "Value(data=6.0, grad=0)\n",
            "Value(data=6.0, grad=0)\n",
            "Value(data=4.0, grad=0)\n",
            "Value(data=-1, grad=0)\n",
            "Value(data=0.0, grad=0)\n",
            "Value(data=3, grad=0)\n",
            "Value(data=0.0, grad=0)\n",
            "Value(data=0.0, grad=0)\n",
            "Value(data=-8.0, grad=0)\n",
            "Value(data=8.0, grad=0)\n",
            "Value(data=0.0, grad=0)\n",
            "Value(data=0.0, grad=0)\n",
            "Value(data=2, grad=0)\n",
            "Value(data=0, grad=0)\n",
            "Value(data=-2.0, grad=0)\n",
            "Value(data=-1, grad=0)\n",
            "Value(data=0.2040816326530612, grad=0)\n",
            "Value(data=10.0, grad=0)\n",
            "Value(data=0.02040816326530612, grad=0)\n"
          ]
        }
      ],
      "source": [
        "test_more_ops()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MRuSrP7JQ00i",
        "1b95Z8u7Q3OL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
